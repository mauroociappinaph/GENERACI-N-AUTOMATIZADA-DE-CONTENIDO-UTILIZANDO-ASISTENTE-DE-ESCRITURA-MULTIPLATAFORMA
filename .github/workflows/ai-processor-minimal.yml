name: AI Processor Minimal
# Sistema mÃ­nimo de IA - GRATIS 24/7

on:
  schedule:
    - cron: '*/5 * * * *'  # Cada 5 minutos
  workflow_dispatch:

env:
  GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
  TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
  TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}

jobs:
  process-ai:
    runs-on: ubuntu-latest
    timeout-minutes: 4

    steps:
    - uses: actions/checkout@v4

    - uses: actions/setup-node@v4
      with:
        node-version: '18'

    - name: Process AI requests
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        # Buscar issues con label 'ai-request'
        AI_ISSUES=$(gh issue list --label "ai-request" --state open --json number,title,body --limit 3)

        if [ "$AI_ISSUES" = "[]" ]; then
          echo "No AI requests found"
          exit 0
        fi

        # Instalar dependencias mÃ­nimas
        npm init -y
        npm install node-fetch@2

        # Crear script de procesamiento
        cat > process.js << 'EOF'
        const fetch = require('node-fetch');

        class MinimalAI {
          async process(prompt) {
            const response = await fetch('https://api.groq.com/openai/v1/chat/completions', {
              method: 'POST',
              headers: {
                'Authorization': `Bearer ${process.env.GROQ_API_KEY}`,
                'Content-Type': 'application/json'
              },
              body: JSON.stringify({
                model: 'llama3-8b-8192',
                messages: [
                  { role: 'system', content: 'Eres un asistente de IA especializado en desarrollo.' },
                  { role: 'user', content: prompt }
                ],
                max_tokens: 1500,
                temperature: 0.7
              })
            });

            const data = await response.json();
            return data.choices[0].message.content;
          }
        }

        async function main() {
          const issues = JSON.parse(process.env.AI_ISSUES || '[]');
          const ai = new MinimalAI();

          for (const issue of issues) {
            try {
              console.log(`Processing issue #${issue.number}`);
              const result = await ai.process(`TÃ­tulo: ${issue.title}\n\nDescripciÃ³n: ${issue.body}`);

              // Agregar comentario al issue
              const { execSync } = require('child_process');
              const comment = `ðŸ¤– **Respuesta de IA AutomÃ¡tica**\n\n${result}\n\n*Procesado automÃ¡ticamente - Costo: $0.00*`;
              execSync(`gh issue comment ${issue.number} --body "${comment.replace(/"/g, '\\"')}"`);

              // Cambiar label
              execSync(`gh issue edit ${issue.number} --remove-label "ai-request" --add-label "ai-completed"`);

              console.log(`âœ… Issue #${issue.number} processed`);

              // Notificar a Telegram si estÃ¡ configurado
              if (process.env.TELEGRAM_BOT_TOKEN && process.env.TELEGRAM_CHAT_ID) {
                await fetch(`https://api.telegram.org/bot${process.env.TELEGRAM_BOT_TOKEN}/sendMessage`, {
                  method: 'POST',
                  headers: { 'Content-Type': 'application/json' },
                  body: JSON.stringify({
                    chat_id: process.env.TELEGRAM_CHAT_ID,
                    text: `ðŸ¤– IA completada\\n\\nIssue #${issue.number}: ${issue.title}\\n\\nCosto: $0.00`,
                    parse_mode: 'Markdown'
                  })
                });
              }

            } catch (error) {
              console.error(`Error processing issue #${issue.number}:`, error.message);
            }
          }
        }

        main().catch(console.error);
        EOF

        # Ejecutar procesamiento
        AI_ISSUES="$AI_ISSUES" node process.js
